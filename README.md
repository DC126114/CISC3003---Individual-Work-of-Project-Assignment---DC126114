
本專案實現了一個基於VGG風格的卷積神經網絡(CNN)模型，用於識別手寫數字（0-9）。模型使用PyTorch框架開發，並通過Gradio實現了互動式網頁界面，讓使用者可以繪製數字並實時獲得識別結果。

## 模型架構

模型採用了VGG風格的CNN架構，分為特徵提取和分類兩部分：

### 特徵提取部分（卷積層）
- **第一卷積塊**：
  - 兩個32通道的3×3卷積層
  - 批量歸一化
  - ReLU激活
  - 最大池化
  - Dropout(0.25)
  
- **第二卷積塊**：
  - 兩個64通道的3×3卷積層
  - 批量歸一化
  - ReLU激活
  - 最大池化
  - Dropout(0.25)
  
- **第三卷積塊**：
  - 兩個128通道的3×3卷積層
  - 批量歸一化
  - ReLU激活
  - 最大池化
  - Dropout(0.25)

### 分類部分（全連接層）
- 扁平化操作
- 全連接層：128×4×4 → 256
- 批量歸一化
- ReLU激活
- Dropout(0.5)
- 輸出層：256 → 10（對應10個數字類別）

## 數據集

使用了標準的32×32像素的手寫數字圖像數據集：
- 訓練集：train_32x32.mat
- 測試集：test_32x32.mat

## 實驗結果

經過多次實驗和超參數調整，模型取得了優異的性能：

| 實驗 | 準確率 | 精確率 | 召回率 | F1分數 |
|------|--------|--------|--------|--------|
| 實驗8 | 96.03% | 95.85% | 95.80% | 95.81% |
| 實驗6 | 95.94% | 95.61% | 95.76% | 95.68% |
| 實驗3 | 95.87% | 95.54% | 95.72% | 95.63% |

- 最佳模型（實驗8）在測試集上達到了96.03%的識別準確率
- 大多數實驗配置都達到了90%以上的準確率
- 實驗7和實驗9表現較差，為我們提供了寶貴的反面教材

## 超參數優化

我們嘗試了多種超參數組合，包括：
- 學習率：0.001 ~ 0.0005
- 批次大小：64 ~ 128
- 優化器：Adam, RMSprop
- Dropout率：0.25 ~ 0.5
- 數據增強參數（旋轉、縮放、翻轉等）

## 項目文件結構

- `model.ipynb`: 主要的模型訓練和實驗代碼
- `CISC3024_project.ipynb`: 完整的模型訓練和評估流程
- `gradio.ipynb`: 基於Gradio的互動式界面實現
- `websiteshow.ipynb`: 網頁展示代碼
- `/models`: 保存了各實驗的模型權重和性能圖表
- `/data`: 包含訓練和測試數據集
- `/Report`: 實驗結果和展示文件

## 互動式界面

項目使用Gradio框架開發了一個使用者友好的界面：
- 使用者可以在網頁上手繪數字
- 模型實時處理並預測數字類別
- 顯示每個類別的預測概率
- 支持圖像預處理和結果可視化

## 使用方法

1. 安裝必要的依賴：
   ```
   pip install torch torchvision numpy gradio matplotlib pillow
   ```

2. 運行互動式界面：
   ```
   python websiteshow.ipynb
   ```

3. 在網頁界面（默認地址：http://127.0.0.1:7863）上繪製數字，系統會實時預測結果。

## 未來改進方向

- 嘗試更複雜的模型架構（ResNet, DenseNet等）
- 實現模型壓縮以減小模型大小
- 提高對不同筆跡和書寫風格的適應能力
- 擴展到更多類別的識別（字母、特殊符號等）
